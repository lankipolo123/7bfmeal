{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1IvPu6y6tk-SonxROrs6ED2tBGVc6_7aQ",
      "authorship_tag": "ABX9TyNdjICui9iqPYyNqUaB3Xnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lankipolo123/7bfmeal/blob/main/Untitled15v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6PwNOkOD6zs",
        "outputId": "08958d4e-5242-41c0-d2fb-a6536437d678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/pothole-4 to yolov8:: 100%|██████████| 72322/72322 [00:03<00:00, 18249.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/pothole-4 in yolov8:: 100%|██████████| 2378/2378 [00:00<00:00, 7267.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset downloaded to: /content/pothole-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q roboflow\n",
        "\n",
        "# Connect to Roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"SzttdelfmuWaCwAz2N5u\")\n",
        "\n",
        "# Load your project and version\n",
        "project = rf.workspace(\"dequillaprojects\").project(\"pothole-ol3a7\")\n",
        "version = project.version(3)\n",
        "\n",
        "# 🔁 Manually set the output directory to pothole-4\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# If pothole-4 exists, remove it to start fresh\n",
        "if os.path.exists(\"/content/pothole-4\"):\n",
        "    shutil.rmtree(\"/content/pothole-4\")\n",
        "\n",
        "# Download into pothole-4\n",
        "dataset = version.download(\"yolov8\", location=\"/content/pothole-4\")\n",
        "\n",
        "# Confirm location\n",
        "print(\"✅ Dataset downloaded to:\", dataset.location)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_yaml = \"\"\"\n",
        "train: ../train/images\n",
        "val: ../valid/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 2\n",
        "names: ['Pothole', 'Sewage-Manhole']\n",
        "\n",
        "roboflow:\n",
        "  license: CC BY 4.0\n",
        "  project: pothole-ol3a7\n",
        "  url: https://universe.roboflow.com/dequillaprojects/pothole-ol3a7/dataset/3\n",
        "  version: 3\n",
        "  workspace: dequillaprojects\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/pothole-4/data.yaml\", \"w\") as f:\n",
        "    f.write(data_yaml.strip())\n",
        "\n",
        "print(\"✅ data.yaml updated with both Pothole and Sewage-Manhole\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBSNXx9QNPYb",
        "outputId": "038f7f84-1480-404f-99e6-3fbb0f3e0088"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ data.yaml updated with both Pothole and Sewage-Manhole\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Ultralytics\n",
        "!pip install -q ultralytics\n",
        "\n",
        "# Step 2: Upload your trained model\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload your best.pt or best2.pt\n",
        "\n",
        "# Step 3: Import and load the model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Replace 'best.pt' with your uploaded file name if different\n",
        "model = YOLO(\"best2.pt\")\n",
        "\n",
        "# Step 4: Train (fine-tune) the model using your updated data.yaml\n",
        "results = model.train(\n",
        "    data=\"/content/pothole-4/data.yaml\",  # Already contains both classes\n",
        "    epochs=30,        # Lower epochs for fine-tuning\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name=\"pothole-v4-finetuned\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GPVCbDBsOcdd",
        "outputId": "b28d4eb3-bdf6-4523-e47b-d7d66d9efc9a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc55f325-0bf0-4b0a-bb5f-241fa856ff09\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc55f325-0bf0-4b0a-bb5f-241fa856ff09\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best2.pt to best2 (4).pt\n",
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/pothole-4/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=best2.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=pothole-v4-finetuned, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/pothole-v4-finetuned, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1449.7±317.9 MB/s, size: 70.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/pothole-4/train/labels... 667 images, 0 backgrounds, 0 corrupt: 100%|██████████| 667/667 [00:00<00:00, 1588.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/pothole-4/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 431.6±93.8 MB/s, size: 63.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pothole-4/valid/labels... 325 images, 0 backgrounds, 0 corrupt: 100%|██████████| 325/325 [00:00<00:00, 1305.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/pothole-4/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/pothole-v4-finetuned/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/pothole-v4-finetuned\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30      4.28G      1.611      1.389      1.652         34        640: 100%|██████████| 42/42 [00:11<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.681       0.62      0.659      0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30      5.04G      1.531      1.143      1.502         61        640: 100%|██████████| 42/42 [00:10<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.691      0.623       0.66       0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30      5.04G      1.484      1.189      1.478         57        640: 100%|██████████| 42/42 [00:10<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888       0.67      0.672      0.709      0.379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30      5.04G       1.48      1.117      1.442         68        640: 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888       0.69      0.577      0.628      0.321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30      5.04G      1.454      1.145      1.463         66        640: 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888       0.63      0.544       0.61      0.318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30      5.04G      1.414      1.087      1.417         66        640: 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888       0.72      0.709      0.758      0.419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30      5.04G      1.399      1.072      1.401         43        640: 100%|██████████| 42/42 [00:10<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.726      0.704      0.751       0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30      5.04G      1.359      1.015      1.394         39        640: 100%|██████████| 42/42 [00:10<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.782      0.671       0.75       0.43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30      5.06G      1.291     0.9756      1.368         70        640: 100%|██████████| 42/42 [00:10<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.751      0.653      0.744      0.417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30       5.1G      1.298     0.9547      1.367         38        640: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.737      0.636      0.715      0.398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30      5.14G      1.262     0.9152      1.331         40        640: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.761      0.709      0.772      0.443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30      5.17G      1.269     0.9263      1.337         52        640: 100%|██████████| 42/42 [00:10<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.748      0.685      0.761      0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30      5.21G      1.276     0.9068      1.348         55        640: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.784      0.718      0.791      0.464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30      5.25G      1.222     0.9218      1.305         78        640: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.768      0.717      0.794      0.475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30      5.28G      1.202     0.8708      1.292         52        640: 100%|██████████| 42/42 [00:10<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888       0.79      0.725      0.784      0.458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30      5.32G      1.145     0.7937      1.254         47        640: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.788      0.723      0.797      0.473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30      5.35G      1.139     0.7959      1.249         44        640: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.814      0.743      0.817      0.475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30      5.39G      1.132     0.7925       1.25         64        640: 100%|██████████| 42/42 [00:10<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.795      0.741      0.815       0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30      5.43G       1.11     0.7755      1.257         52        640: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.838      0.739      0.833      0.503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30      5.46G      1.088     0.7568      1.233         77        640: 100%|██████████| 42/42 [00:10<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.842      0.747       0.84      0.524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30       5.5G      1.037     0.6844      1.213         52        640: 100%|██████████| 42/42 [00:10<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.809      0.777      0.842      0.515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      5.54G     0.9852     0.5995      1.167         18        640: 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.811      0.779      0.833      0.509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30      5.57G     0.9921     0.6017      1.173         28        640: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.842      0.759      0.852      0.529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      5.61G     0.9417     0.5658      1.135         20        640: 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.844      0.775      0.853      0.534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30      5.65G     0.9087     0.5461      1.112         38        640: 100%|██████████| 42/42 [00:10<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.852      0.782       0.86      0.537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      5.68G     0.9283     0.5433      1.129         20        640: 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.871      0.773      0.867       0.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      5.72G     0.9251      0.557      1.136         21        640: 100%|██████████| 42/42 [00:10<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.848       0.79      0.864      0.545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      5.76G     0.8735     0.5137      1.097         30        640: 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888       0.84      0.796      0.862       0.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      5.79G     0.8415     0.4879      1.072         21        640: 100%|██████████| 42/42 [00:10<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.844      0.798      0.866       0.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      5.83G     0.8217     0.4687      1.069         36        640: 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.845      0.793      0.869      0.556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 0.112 hours.\n",
            "Optimizer stripped from runs/detect/pothole-v4-finetuned/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/pothole-v4-finetuned/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/pothole-v4-finetuned/weights/best.pt...\n",
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:03<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.848      0.794       0.87      0.556\n",
            "               Pothole        325        888      0.848      0.794       0.87      0.556\n",
            "Speed: 0.2ms preprocess, 4.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/pothole-v4-finetuned\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nano training"
      ],
      "metadata": {
        "id": "Ct61XaQTTPcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 1: Install required libraries\n",
        "!pip install -q roboflow\n",
        "!pip install -q ultralytics --upgrade\n",
        "\n",
        "# ✅ STEP 2: Upload your pretrained model (optional for fine-tuning)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload your best.pt here\n",
        "\n",
        "# ✅ STEP 3: Download dataset from Roboflow (version 4)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"SzttdelfmuWaCwAz2N5u\")\n",
        "project = rf.workspace(\"dequillaprojects\").project(\"pothole-ol3a7\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n",
        "# ✅ STEP 4: Fix and overwrite data.yaml (force correct class list)\n",
        "data_yaml_path = f\"{dataset.location}/data.yaml\"\n",
        "\n",
        "updated_yaml = \"\"\"\n",
        "names:\n",
        "- Pothole\n",
        "- Sewage-Manhole\n",
        "nc: 2\n",
        "roboflow:\n",
        "  license: CC BY 4.0\n",
        "  project: pothole-ol3a7\n",
        "  url: https://universe.roboflow.com/dequillaprojects/pothole-ol3a7/dataset/4\n",
        "  version: 4\n",
        "  workspace: dequillaprojects\n",
        "test: ../test/images\n",
        "train: ../train/images\n",
        "val: ../valid/images\n",
        "\"\"\"\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    f.write(updated_yaml)\n",
        "\n",
        "# ✅ STEP 5: Load YOLOv8n (Nano) and train it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Use your uploaded model if available; else use YOLOv8n base\n",
        "model = YOLO(\"best.pt\") if \"best.pt\" in uploaded else YOLO(\"yolov8n.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name=\"pothole-n-v5-finetune\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sjKkKGyTTQp4",
        "outputId": "7b7672f7-06c7-4508-9821-700cec886051"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7e7e69a9-e5d8-45f7-aa4f-faffda63c99c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7e7e69a9-e5d8-45f7-aa4f-faffda63c99c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best.pt to best (2).pt\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 16.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/pothole-3/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=pothole-n-v5-finetune, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/pothole-n-v5-finetune, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1455.5±184.6 MB/s, size: 70.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/pothole-3/train/labels.cache... 667 images, 0 backgrounds, 0 corrupt: 100%|██████████| 667/667 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 518.6±127.3 MB/s, size: 63.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pothole-3/valid/labels.cache... 325 images, 0 backgrounds, 0 corrupt: 100%|██████████| 325/325 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/pothole-n-v5-finetune/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/pothole-n-v5-finetune\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      2.75G      1.748      2.748      1.727         34        640: 100%|██████████| 42/42 [00:06<00:00,  6.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.774        0.1      0.284      0.138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      3.13G      1.645      2.043      1.601         61        640: 100%|██████████| 42/42 [00:06<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.331      0.294      0.223     0.0953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      3.13G      1.657      1.963      1.632         57        640: 100%|██████████| 42/42 [00:06<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.317       0.35      0.253      0.107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      3.13G      1.678      1.853      1.614         68        640: 100%|██████████| 42/42 [00:06<00:00,  6.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.383      0.454      0.368      0.166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      3.13G      1.682      1.824      1.642         66        640: 100%|██████████| 42/42 [00:06<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888       0.44      0.301      0.286      0.117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      3.13G      1.636      1.695      1.565         66        640: 100%|██████████| 42/42 [00:06<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.536      0.482      0.506      0.221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      3.13G      1.626      1.663      1.566         43        640: 100%|██████████| 42/42 [00:06<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.582       0.48      0.504      0.244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      3.13G      1.609      1.605      1.573         39        640: 100%|██████████| 42/42 [00:05<00:00,  7.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.583       0.53       0.55      0.272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      3.13G      1.549      1.539      1.532         70        640: 100%|██████████| 42/42 [00:06<00:00,  6.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.602      0.505      0.523      0.245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      3.13G      1.527      1.456      1.504         38        640: 100%|██████████| 42/42 [00:06<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  5.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.664      0.582      0.618      0.305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      3.13G        1.5      1.403      1.479         40        640: 100%|██████████| 42/42 [00:06<00:00,  6.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  5.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.699      0.584      0.661      0.334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      3.13G      1.514      1.407      1.504         52        640: 100%|██████████| 42/42 [00:06<00:00,  6.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.646      0.618      0.663      0.329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      3.13G       1.51      1.388      1.499         55        640: 100%|██████████| 42/42 [00:06<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.632      0.578      0.626      0.321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      3.13G      1.476      1.394      1.474         78        640: 100%|██████████| 42/42 [00:06<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.726       0.57      0.675      0.344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      3.13G      1.476      1.325      1.488         52        640: 100%|██████████| 42/42 [00:06<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.703      0.637      0.691      0.356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      3.13G      1.442       1.26      1.437         47        640: 100%|██████████| 42/42 [00:06<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.724       0.62      0.699      0.364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      3.13G      1.437      1.283      1.429         44        640: 100%|██████████| 42/42 [00:06<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.708      0.651      0.706      0.384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      3.13G      1.434      1.256      1.437         64        640: 100%|██████████| 42/42 [00:06<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.725      0.659      0.717      0.394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      3.13G      1.397      1.239      1.426         52        640: 100%|██████████| 42/42 [00:06<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.721      0.685      0.733      0.404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      3.13G      1.402      1.215      1.432         77        640: 100%|██████████| 42/42 [00:06<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.712      0.673      0.744      0.405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      3.13G      1.351      1.173      1.375         63        640: 100%|██████████| 42/42 [00:06<00:00,  6.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.723      0.678      0.753      0.422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      3.13G      1.383      1.149        1.4         57        640: 100%|██████████| 42/42 [00:06<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.707      0.674      0.724      0.389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      3.13G      1.341      1.134      1.384         45        640: 100%|██████████| 42/42 [00:06<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.758      0.663       0.75      0.412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      3.13G      1.363      1.136      1.377         50        640: 100%|██████████| 42/42 [00:06<00:00,  6.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.755      0.715       0.77      0.421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      3.13G      1.311      1.112      1.357         78        640: 100%|██████████| 42/42 [00:06<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.736      0.667      0.732      0.417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      3.13G      1.294      1.066      1.352         67        640: 100%|██████████| 42/42 [00:06<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888       0.76      0.685      0.779      0.442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      3.13G      1.297      1.045       1.35         54        640: 100%|██████████| 42/42 [00:06<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888       0.78      0.717      0.799      0.457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      3.13G      1.307      1.061      1.334         56        640: 100%|██████████| 42/42 [00:06<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.764      0.707      0.778      0.448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      3.13G      1.271      1.039      1.346         32        640: 100%|██████████| 42/42 [00:06<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.801      0.729      0.803      0.468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      3.13G      1.273      1.035      1.338         35        640: 100%|██████████| 42/42 [00:06<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.783      0.699      0.786      0.465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      3.13G       1.26      1.019      1.319         57        640: 100%|██████████| 42/42 [00:06<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.779      0.691      0.787      0.467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      3.13G      1.261     0.9965      1.316         49        640: 100%|██████████| 42/42 [00:06<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.763      0.727      0.796      0.463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      3.13G      1.204       0.97      1.289         53        640: 100%|██████████| 42/42 [00:06<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.783      0.752      0.815      0.489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      3.13G      1.214     0.9609      1.297         55        640: 100%|██████████| 42/42 [00:05<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.787      0.737       0.81      0.485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      3.13G       1.24     0.9701      1.283         64        640: 100%|██████████| 42/42 [00:06<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.787      0.749      0.806      0.484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      3.13G      1.166     0.9171      1.273         39        640: 100%|██████████| 42/42 [00:06<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.797      0.764      0.825      0.498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      3.13G      1.163     0.9186      1.263         49        640: 100%|██████████| 42/42 [00:06<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.811       0.76       0.83      0.504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      3.13G       1.18     0.9253      1.266         61        640: 100%|██████████| 42/42 [00:06<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.803      0.758      0.831      0.512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      3.13G      1.157      0.875      1.254         35        640: 100%|██████████| 42/42 [00:06<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.799      0.738      0.819      0.496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      3.13G      1.165      0.862       1.25         38        640: 100%|██████████| 42/42 [00:06<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.793      0.768      0.829      0.504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      3.13G      1.101     0.8401      1.242         17        640: 100%|██████████| 42/42 [00:06<00:00,  6.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.781      0.752      0.831        0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      3.13G      1.081      0.755      1.215         40        640: 100%|██████████| 42/42 [00:06<00:00,  6.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.813      0.768      0.838      0.507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      3.13G       1.06      0.752      1.203         28        640: 100%|██████████| 42/42 [00:05<00:00,  7.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.802      0.761       0.84      0.509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      3.13G      1.058     0.7334      1.206         32        640: 100%|██████████| 42/42 [00:06<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.853      0.748      0.844      0.524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      3.13G      1.016     0.7005      1.178         17        640: 100%|██████████| 42/42 [00:06<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.816      0.778       0.85      0.522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      3.13G      1.004     0.6857      1.162         39        640: 100%|██████████| 42/42 [00:05<00:00,  7.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.846       0.76      0.852      0.529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      3.13G      1.011     0.6932      1.168         41        640: 100%|██████████| 42/42 [00:06<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.829      0.761      0.853      0.535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      3.13G     0.9943      0.676      1.152         26        640: 100%|██████████| 42/42 [00:06<00:00,  6.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.838      0.765      0.858      0.537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      3.13G      0.972     0.6626      1.152         38        640: 100%|██████████| 42/42 [00:05<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.824      0.765      0.855      0.535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      3.13G     0.9522     0.6342       1.13         33        640: 100%|██████████| 42/42 [00:06<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:01<00:00,  6.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.836      0.769      0.857      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 0.114 hours.\n",
            "Optimizer stripped from runs/detect/pothole-n-v5-finetune/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/pothole-n-v5-finetune/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/pothole-n-v5-finetune/weights/best.pt...\n",
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:02<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        325        888      0.837      0.769      0.857      0.538\n",
            "               Pothole        325        888      0.837      0.769      0.857      0.538\n",
            "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/pothole-n-v5-finetune\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "quantized"
      ],
      "metadata": {
        "id": "ZfBr4ynFYUzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install required packages\n",
        "!pip install ultralytics onnx onnxruntime onnxsim onnxslim --quiet\n",
        "\n",
        "# ✅ Step 2: Upload both model files\n",
        "from google.colab import files\n",
        "\n",
        "print(\"🔼 Please upload your .pt files (e.g., bestn85.pt and best87.pt)...\")\n",
        "uploaded = files.upload()  # Hold Ctrl or Cmd to select both\n",
        "\n",
        "# ✅ Step 3: Convert each model to ONNX, TFLite (non-quantized and quantized)\n",
        "from ultralytics import YOLO\n",
        "\n",
        "for model_name in uploaded.keys():\n",
        "    if not model_name.endswith(\".pt\"):\n",
        "        continue  # skip any non-pt files\n",
        "\n",
        "    print(f\"\\n🚀 Processing model: {model_name}\")\n",
        "    model = YOLO(model_name)\n",
        "\n",
        "    # Export to ONNX\n",
        "    print(\"📦 Exporting to ONNX...\")\n",
        "    model.export(format=\"onnx\", dynamic=True)\n",
        "\n",
        "    # Export to TFLite (non-quantized)\n",
        "    print(\"📦 Exporting to TFLite (non-quantized)...\")\n",
        "    model.export(format=\"tflite\", int8=False)\n",
        "\n",
        "    # Export to TFLite (quantized)\n",
        "    print(\"📦 Exporting to TFLite (quantized)...\")\n",
        "    model.export(format=\"tflite\", int8=True)\n",
        "\n",
        "print(\"\\n✅ All conversions complete! Files are saved in /content\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EWkeTRzjYUgv",
        "outputId": "a892fc7b-811c-499f-f200-b8917ec1dfee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m🔼 Please upload your .pt files (e.g., bestn85.pt and best87.pt)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-29f6d56b-7f05-4cc3-9b09-9dab52dbc162\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-29f6d56b-7f05-4cc3-9b09-9dab52dbc162\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bestn85.pt to bestn85 (2).pt\n",
            "Saving best87.pt to best87.pt\n",
            "\n",
            "🚀 Processing model: bestn85 (2).pt\n",
            "📦 Exporting to ONNX...\n",
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'bestn85 (2).pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (6.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 6.6s, saved as 'bestn85 (2).onnx' (11.6 MB)\n",
            "\n",
            "Export complete (6.9s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=bestn85 (2).onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=bestn85 (2).onnx imgsz=640 data=/content/pothole-3/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "📦 Exporting to TFLite (non-quantized)...\n",
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'bestn85 (2).pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (6.0 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0,<1.4.0', 'onnx2tf>=1.26.3', 'protobuf>=5'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 7.2s\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.11M/1.11M [00:00<00:00, 4.34MB/s]\n",
            "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|██████████| 1/1 [00:00<00:00, 48.89file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.0s, saved as 'bestn85 (2).onnx' (11.7 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.2...\n",
            "Saved artifact at 'bestn85 (2)_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 6, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136744390009936: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744390009552: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  136744390010320: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136744390012048: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744390014352: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  136744390013968: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744390014928: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744390015312: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744390015888: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390015696: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390015504: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  136744390016848: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136744390015120: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  136744390016464: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136744390016080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390016272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388216400: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
            "  136744388216784: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388216976: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388216016: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  136744388215248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388217168: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388217552: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388218128: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388217936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388218896: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388220240: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388217744: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388217360: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388220624: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388220432: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388219088: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388219664: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388218320: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388218512: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388221200: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  136744388221008: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388221392: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388219472: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  136744388220816: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388221584: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744388221968: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388222544: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388222352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388223312: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388224656: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388222160: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388221776: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388225040: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388224848: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388223888: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388225232: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388222736: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388222928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388225616: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136744388224080: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388225808: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388223504: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  136744388225424: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744388226000: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136744388226384: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744388226960: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388226768: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388227728: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744388229072: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388226576: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744388226192: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388227152: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388227344: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388229264: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136744388229456: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744388227920: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136744388228496: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388229840: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136744388229648: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744388230032: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  136744388230224: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388362896: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388363280: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388230608: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388228304: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388230800: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388230416: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388230992: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388362320: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388364432: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136744388362704: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388364240: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
            "  136744388363472: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388365008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388364816: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388365776: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388367120: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388364624: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388364048: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388365200: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388365392: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388366544: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  136744388366352: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388365968: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388367312: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388367504: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388369232: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136744388369424: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388370768: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388370384: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388373456: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388373264: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388372496: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388371920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388371152: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388371344: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388372304: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136744388370576: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388371728: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388373072: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744388370960: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388375184: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136744388375376: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744388376720: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388376336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378581456: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744378581840: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388378256: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744388377872: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388377104: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388377296: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388377680: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136744388376528: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744378581648: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136744388378448: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136744388374032: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136744388373648: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136744388368080: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388367696: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378582032: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388376912: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388374224: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388373840: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388368272: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388367888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378582224: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378582608: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388374416: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388374608: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388368464: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388368656: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378582416: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378582800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388374800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388374992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388368848: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388369040: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378582992: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
            "  136744378583376: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388376144: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
            "  136744388375568: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388369616: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
            "  136744388370192: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378583568: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378583184: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136744388375760: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388375952: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136744388369808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388370000: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136744378586064: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744378585872: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744378586256: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  136744378586448: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744378584336: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744378586640: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744378585104: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744378588560: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136744378583760: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136744378585296: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744378585488: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 29.3s, saved as 'bestn85 (2)_saved_model' (29.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as 'bestn85 (2)_saved_model/bestn85 (2)_float32.tflite' (11.7 MB)\n",
            "\n",
            "Export complete (29.6s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=bestn85 (2)_saved_model/bestn85 (2)_float32.tflite imgsz=640  \n",
            "Validate:        yolo val task=detect model=bestn85 (2)_saved_model/bestn85 (2)_float32.tflite imgsz=640 data=/content/pothole-3/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "📦 Exporting to TFLite (quantized)...\n",
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "WARNING ⚠️ INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'bestn85 (2).pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (6.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.2s, saved as 'bestn85 (2).onnx' (11.7 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=coco8.yaml'\n",
            "\n",
            "WARNING ⚠️ Dataset 'coco8.yaml' images not found, missing path '/content/datasets/coco8/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 433k/433k [00:00<00:00, 2.16MB/s]\n",
            "Unzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100%|██████████| 25/25 [00:00<00:00, 4615.01file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ✅ (1.3s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Fast image access ✅ (ping: 0.0±0.0 ms, read: 1273.6±224.3 MB/s, size: 54.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Scanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 1768.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New cache created: /content/datasets/coco8/labels/val.cache\n",
            "WARNING ⚠️ \u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m >300 images recommended for INT8 calibration, found 4 images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.2...\n",
            "Saved artifact at 'bestn85 (2)_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 6, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136744388217552: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388216400: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  136744388217744: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136744388217936: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388218128: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  136744388220240: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388218896: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388220624: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388219664: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388219088: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388221008: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  136744388222352: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136744388220432: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  136744388217360: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136744388218320: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388218512: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388223312: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
            "  136744388224656: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388221584: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388221392: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  136744388220816: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388222160: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388225040: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388225232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388223888: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388224080: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388226768: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388224848: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388221776: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388229072: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388227728: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388225808: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744388226000: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388222736: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388222928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388227152: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  136744388226192: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388226576: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388229264: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  136744388227920: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388227344: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744388229840: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388229648: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388228496: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388228304: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388227536: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388225424: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388229456: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388224272: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388224464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388230800: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388228880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744388230032: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388230224: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388220048: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136744388223120: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388219856: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388230992: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  136744388223696: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744388219280: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136744388214864: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744390006864: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390009936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388216208: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744388218704: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744388215440: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744388215056: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743677463824: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743677464016: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390013968: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136744390014928: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744390014352: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136744390009552: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744390015888: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136744390015312: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744390015696: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  136744390015504: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744390016464: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390015120: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390010896: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744390012240: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744390016848: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744390014160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744390016080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390016272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390010704: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136744390013584: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744390010512: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
            "  136744390013776: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744390006672: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390003408: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390011664: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744390009360: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744390011472: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136744390006096: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744390007056: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390005904: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744390006288: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  136744378582608: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378582416: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744378582800: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378581648: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378584336: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136744378586640: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744378588176: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378585488: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378589328: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378581264: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378591056: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378589904: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378587792: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378584144: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378590288: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136744378590096: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744378590672: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744378590480: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744378587600: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744378592592: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136744378592784: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744378593936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378593552: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378596816: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744378597008: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744378597200: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136746054336784: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744378594320: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378594512: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054337168: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136746054336592: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136746054337744: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136746054337360: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136744378591440: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136744378589136: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136744378583568: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378582992: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054336976: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054337552: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378590864: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378591248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378583184: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378583376: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054337936: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054338320: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378592208: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378592016: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378586064: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378585872: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054338128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054338512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378592400: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378591824: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378586256: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378586448: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054338704: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
            "  136746054339088: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378588944: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
            "  136744378593360: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744378585104: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
            "  136744378585296: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054339280: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054338896: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136744378593168: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378592976: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136744378588560: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744378583760: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136746054342160: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136746054341968: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136746054342352: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  136746054345616: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136746054345040: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136746054345808: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136746054346000: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136746054348112: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136746054346576: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136746054341392: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136746054341584: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 49.6s, saved as 'bestn85 (2)_saved_model' (38.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as 'bestn85 (2)_saved_model/bestn85 (2)_int8.tflite' (3.1 MB)\n",
            "\n",
            "Export complete (49.9s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=bestn85 (2)_saved_model/bestn85 (2)_int8.tflite imgsz=640 int8 \n",
            "Validate:        yolo val task=detect model=bestn85 (2)_saved_model/bestn85 (2)_int8.tflite imgsz=640 data=/content/pothole-3/data.yaml int8 \n",
            "Visualize:       https://netron.app\n",
            "\n",
            "🚀 Processing model: best87.pt\n",
            "📦 Exporting to ONNX...\n",
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best87.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (21.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 5.8s, saved as 'best87.onnx' (42.5 MB)\n",
            "\n",
            "Export complete (6.4s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=best87.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=best87.onnx imgsz=640 data=/content/pothole-4/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "📦 Exporting to TFLite (non-quantized)...\n",
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best87.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (21.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.8s, saved as 'best87.onnx' (42.7 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.2...\n",
            "Saved artifact at 'best87_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 6, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136744378596240: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744378596432: TensorSpec(shape=(3, 3, 3, 32), dtype=tf.float32, name=None)\n",
            "  136744378595088: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136746054348880: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136746054349264: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  136746054349072: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054348688: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054339472: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054340624: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054340432: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054343312: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136746054344464: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136746054340240: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136746054339664: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136746054340816: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054340048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054344656: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  136746054344848: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054343504: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136746054342736: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  136746054341200: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136746054342544: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136746054347152: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136746054347920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054348304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744197110672: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054350800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054346960: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054344080: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054348496: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054349456: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054349840: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744388215248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054345424: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054345232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744388216016: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136744388216784: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744390011856: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136742301120656: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  136744390006480: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744248770640: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136744248771024: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744248771600: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248771408: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248772368: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744248773712: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248771216: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744248770832: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248774096: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744248773904: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248772560: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744248773136: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248771792: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248771984: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248774672: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136744248774480: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744248774864: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744248772944: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
            "  136744248774288: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136744248775056: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  136744248775440: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136744248776016: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248775824: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248776784: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136744248778128: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744248775632: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136744248775248: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744248776208: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248776400: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248778320: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
            "  136744248778512: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136744248776976: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136744248777552: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744248779088: TensorSpec(shape=(1, 1, 1024, 512), dtype=tf.float32, name=None)\n",
            "  136744248778896: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136744248778704: TensorSpec(shape=(1, 1, 768, 256), dtype=tf.float32, name=None)\n",
            "  136744248779280: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744248779856: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248779664: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248780624: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744248781968: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248779472: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744248777360: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248780048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248780240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248782352: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136744248781200: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744248782160: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  136744248781392: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248782928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248782736: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248783696: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744248785040: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744248782544: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744248780816: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744248783120: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248783312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744248785424: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136744248784272: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248784464: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744248785232: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744248783888: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743341703440: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136743341703632: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743341704976: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743341704592: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743341707664: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743341707472: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743341708048: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743341708240: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743341705360: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743341705552: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743341707856: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136743341706704: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743341708816: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136743341708624: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136743341708432: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743341710544: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
            "  136743341710736: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136743341712080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743341711696: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743341714768: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136743341714576: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743341713808: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136743341715152: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743341712464: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743341712656: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743341715536: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
            "  136743341715344: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136743341716112: TensorSpec(shape=(3, 3, 512, 128), dtype=tf.float32, name=None)\n",
            "  136743341715728: TensorSpec(shape=(3, 3, 512, 64), dtype=tf.float32, name=None)\n",
            "  136743341709392: TensorSpec(shape=(3, 3, 256, 128), dtype=tf.float32, name=None)\n",
            "  136743341709008: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136744248786000: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744248785616: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136743341714960: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743341715920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743341709584: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743341709200: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744248786192: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248785808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743341716304: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743341716688: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136743341709776: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743341709968: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744248786768: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744248786576: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136743341716496: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743341716880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743341710160: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743341710352: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743341703248: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744248786384: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743341717072: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
            "  136743341717456: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136743341710928: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
            "  136743341711504: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136743341703824: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
            "  136743341704400: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136743341717648: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743341717264: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136743341711120: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743341711312: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136743341704016: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743341704208: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136743191495312: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136743191495120: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136743191495888: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  136743191498768: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136743191498192: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136743191498960: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136743191499152: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136743191501264: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136743191499728: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136743191494736: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136743191495504: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 17.0s, saved as 'best87_saved_model' (106.9 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as 'best87_saved_model/best87_float32.tflite' (42.7 MB)\n",
            "\n",
            "Export complete (17.6s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=best87_saved_model/best87_float32.tflite imgsz=640  \n",
            "Validate:        yolo val task=detect model=best87_saved_model/best87_float32.tflite imgsz=640 data=/content/pothole-4/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "📦 Exporting to TFLite (quantized)...\n",
            "Ultralytics 8.3.171 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "WARNING ⚠️ INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best87.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (21.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.9s, saved as 'best87.onnx' (42.7 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=coco8.yaml'\n",
            "Fast image access ✅ (ping: 0.0±0.0 ms, read: 1450.1±162.1 MB/s, size: 54.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ \u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m >300 images recommended for INT8 calibration, found 4 images.\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at 'best87_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 6, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136744197110864: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744197110672: TensorSpec(shape=(3, 3, 3, 32), dtype=tf.float32, name=None)\n",
            "  136744388216016: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136744388216784: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744388215248: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  136744388216976: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054348880: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054349072: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054340624: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054339472: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054347920: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136746054347152: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136746054348304: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136746054342736: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136746054340432: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054343312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054349264: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  136746054339664: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054340048: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136746054340240: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  136746054348688: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136746054342544: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136746054341200: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136746054344080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054346960: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054345424: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054339856: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054350800: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054344656: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054343888: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054344272: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054345232: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746054350032: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746054348496: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746054349456: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378594128: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136744378594896: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744378595664: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136744378595088: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  136744378596432: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136744378596624: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136744378585680: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743191503376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191504144: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136744378595472: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744378593744: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191502992: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743191495888: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191499728: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743191495312: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191499152: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743191498768: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191503952: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191502800: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191502416: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136743191495504: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743191502224: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136743191501264: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
            "  136743191494736: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136743191502032: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  136743191501456: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136743191500112: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191500304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191500688: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136743191497808: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743191498576: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136743191498384: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743191501072: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191499536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191497616: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
            "  136743191497424: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136743191500496: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136743191496464: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743191497040: TensorSpec(shape=(1, 1, 1024, 512), dtype=tf.float32, name=None)\n",
            "  136743191497232: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136743191496656: TensorSpec(shape=(1, 1, 768, 256), dtype=tf.float32, name=None)\n",
            "  136743191496848: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743191494928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191496080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191505104: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743191506256: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191496272: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743191499344: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191505296: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191501648: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191506640: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136743191505680: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136743191506448: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  136743191505872: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191507216: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191507024: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191507984: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136743191508560: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743191506832: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136743191504336: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743191507408: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191507600: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191509712: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136743191508752: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191509136: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136743191509520: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743191507792: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136746049618384: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136746049618576: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136746049619920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746049619536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746049622608: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136746049622416: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136746049620112: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136746049621072: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136746049620304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746049620496: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746049622224: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136746049619728: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136746049621456: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136746049620880: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136746049622800: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136746049624336: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
            "  136746049624528: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136746049625872: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746049625488: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743677463824: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136743677464016: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136742301120656: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136743191503760: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136746049626256: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136746049626448: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136743191501840: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
            "  136744197111632: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136744197110480: TensorSpec(shape=(3, 3, 512, 128), dtype=tf.float32, name=None)\n",
            "  136744197111056: TensorSpec(shape=(3, 3, 512, 64), dtype=tf.float32, name=None)\n",
            "  136746049623184: TensorSpec(shape=(3, 3, 256, 128), dtype=tf.float32, name=None)\n",
            "  136746049621648: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136743191510288: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743191509904: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136744197111440: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744197111248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746049623376: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136746049622992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136743191510480: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191510096: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744197110288: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136744197109904: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746049623568: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136746049623760: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746049618000: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136743191510864: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744197110096: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136744197109712: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746049623952: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136746049624144: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746049618192: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136743191510672: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744197109520: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
            "  136744197109136: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746049624720: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
            "  136746049625296: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136746049618768: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
            "  136746049619344: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136744197108944: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136744197109328: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136746049624912: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746049625104: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136746049618960: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136746049619152: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "  136744197107792: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744197108560: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744197107600: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  136744197106256: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744197105680: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744197106640: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744197106448: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744197103952: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136744197105296: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136744197108176: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136744197108368: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 81.1s, saved as 'best87_saved_model' (139.3 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as 'best87_saved_model/best87_int8.tflite' (10.9 MB)\n",
            "\n",
            "Export complete (81.7s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=best87_saved_model/best87_int8.tflite imgsz=640 int8 \n",
            "Validate:        yolo val task=detect model=best87_saved_model/best87_int8.tflite imgsz=640 data=/content/pothole-4/data.yaml int8 \n",
            "Visualize:       https://netron.app\n",
            "\n",
            "✅ All conversions complete! Files are saved in /content\n"
          ]
        }
      ]
    }
  ]
}